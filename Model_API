from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
from transformers import BertTokenizer, BertForSequenceClassification
from fastapi.middleware.cors import CORSMiddleware

class Review(BaseModel):
    text: str

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_methods=["*"],  # Allows all methods
    allow_headers=["*"],  # Allows all headers
)

# Load the tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
model.load_state_dict(torch.load("bert_movie_review_model.pth", map_location=torch.device('cpu')))
model.eval()

@app.post("/predict/")
async def predict_sentiment(review: Review):
    with torch.no_grad():
        inputs = tokenizer.encode_plus(
            review.text,
            add_special_tokens=True,
            max_length=128,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt'
        )
        input_ids = inputs['input_ids']
        attention_mask = inputs['attention_mask']

        outputs = model(input_ids, attention_mask=attention_mask)
        prediction = torch.argmax(outputs.logits, dim=1)

        sentiment = 'positive' if prediction.item() == 1 else 'negative'

    return {"sentiment": sentiment}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





# from fastapi import FastAPI, HTTPException
# from fastapi.middleware.cors import CORSMiddleware
# from pydantic import BaseModel
# from transformers import BertTokenizer, BertForSequenceClassification
# from typing import List
# import torch

# app = FastAPI()

# origins = ["*"]

# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=origins,
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # Load your pre-trained BERT model and tokenizer
# model_path = "/Users/gautampirthiani/Desktop/cse5097-final-project-knights"  # Replace with the actual path to your model
# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
# model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)

# # Set the model to evaluation mode
# model.eval()

# class ReviewItem(BaseModel):
#     text: str

# class PredictionResult(BaseModel):
#     predicted_class: int

# @app.post("/predict-sentiment/", response_model=PredictionResult)
# async def predict_sentiment(review_item: ReviewItem):
#     # Tokenize the input text
#     tokens = tokenizer.encode_plus(
#         review_item.text,
#         truncation=True,
#         padding=True,
#         return_tensors='pt',  # Return PyTorch tensors
#     )

#     # Perform inference
#     with torch.no_grad():
#         outputs = model(**tokens)

#     # Get the predicted class
#     predicted_class = torch.argmax(outputs.logits).item()

#     return {"predicted_class": predicted_class}
